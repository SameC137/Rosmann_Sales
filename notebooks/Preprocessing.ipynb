{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Id - an Id that represents a (Store, Date) duple within the test set \\\r\n",
    "Store - a unique Id for each store\\\r\n",
    "Sales - the turnover for any given day (this is what you are predicting)\\\r\n",
    "Customers - the number of customers on a given day\\\r\n",
    "Open - an indicator for whether the store was open: 0 = closed, 1 = open\\\r\n",
    "StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\\\r\n",
    "SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\\\r\n",
    "StoreType - differentiates between 4 different store models: a, b, c, d\\\r\n",
    "Assortment - describes an assortment level: a = basic, b = extra, c = extended\\\r\n",
    "CompetitionDistance - distance in meters to the nearest competitor store\\\r\n",
    "CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\\\r\n",
    "Promo - indicates whether a store is running a promo on that day\\\r\n",
    "Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\\\r\n",
    "Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\\\r\n",
    "PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store \\"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "train = pd.read_csv('../data/train_store_combined.csv')\r\n",
    "test = pd.read_csv('../data/test_store_combined.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "def isWeekend(x):\r\n",
    "    if x<6:\r\n",
    "        return 0\r\n",
    "    else: \r\n",
    "        return 1\r\n",
    "train[\"weekend\"]= train[\"DayOfWeek\"].apply(isWeekend )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "def startMidEndMonth(x):\r\n",
    "    if x<10:\r\n",
    "        return 0\r\n",
    "    elif x<20:\r\n",
    "        return 1\r\n",
    "    else:\r\n",
    "        return 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "train.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count    Dtype  \n",
      "---  ------                     --------------    -----  \n",
      " 0   Store                      1017209 non-null  int64  \n",
      " 1   DayOfWeek                  1017209 non-null  int64  \n",
      " 2   Date                       1017209 non-null  object \n",
      " 3   Sales                      1017209 non-null  int64  \n",
      " 4   Customers                  1017209 non-null  int64  \n",
      " 5   Open                       1017209 non-null  int64  \n",
      " 6   Promo                      1017209 non-null  int64  \n",
      " 7   StateHoliday               1017209 non-null  object \n",
      " 8   SchoolHoliday              1017209 non-null  int64  \n",
      " 9   Year                       1017209 non-null  int64  \n",
      " 10  Month                      1017209 non-null  int64  \n",
      " 11  Day                        1017209 non-null  int64  \n",
      " 12  StoreType                  1017209 non-null  object \n",
      " 13  Assortment                 1017209 non-null  object \n",
      " 14  CompetitionDistance        1014567 non-null  float64\n",
      " 15  CompetitionOpenSinceMonth  693861 non-null   float64\n",
      " 16  CompetitionOpenSinceYear   693861 non-null   float64\n",
      " 17  Promo2                     1017209 non-null  int64  \n",
      " 18  Promo2SinceWeek            509178 non-null   float64\n",
      " 19  Promo2SinceYear            509178 non-null   float64\n",
      " 20  PromoInterval              509178 non-null   object \n",
      " 21  weekend                    1017209 non-null  int64  \n",
      "dtypes: float64(5), int64(12), object(5)\n",
      "memory usage: 170.7+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "train[\"MonthState\"]=train[\"Day\"].apply(startMidEndMonth)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "import bisect\r\n",
    "train[\"Date\"]=pd.to_datetime(train[\"Date\"])\r\n",
    "dates=np.array(train[train[\"StateHoliday\"]!=\"0\"][\"Date\"].unique())\r\n",
    "dates=np.sort(dates)\r\n",
    "a=train[\"Date\"].iloc[119]\r\n",
    "\r\n",
    "index = bisect.bisect(dates, a)\r\n",
    "print(index,dates[index-1],dates[index],a)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32 2015-04-03T00:00:00.000000000 2015-04-06T00:00:00.000000000 2015-04-03 00:00:00\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "def datToAndAfterHoliday(df,Column,holidays):\r\n",
    "    to=[]\r\n",
    "    after=[]\r\n",
    "    for a in df[Column]:\r\n",
    "        index=bisect.bisect(holidays,a)\r\n",
    "        if len(holidays)==index:\r\n",
    "            to.append(pd.Timedelta(0, unit='d') )\r\n",
    "            after.append(a - holidays[index-1])\r\n",
    "        else:\r\n",
    "            after.append(holidays[index] - a)\r\n",
    "            to.append(a -holidays[index-1])\r\n",
    "    return to,after"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "train[\"To\"],train[\"After\"]=datToAndAfterHoliday(train,\"Date\",dates)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "# train['Promo2SinceWeek'] = train['Promo2SinceWeek'].fillna(train['Promo2SinceWeek'].max())\r\n",
    "# train['Promo2SinceYear'] = train['Promo2SinceYear'].fillna(train['Promo2SinceYear'].max())\r\n",
    "# train['PromoInterval'] = train['PromoInterval'].fillna(train['PromoInterval'].mode().iloc[0])\r\n",
    "\r\n",
    "# train['CompetitionDistance'] = train['CompetitionDistance'].fillna(train['CompetitionDistance'].max())\r\n",
    "# train['CompetitionOpenSinceMonth'] = train['CompetitionOpenSinceMonth'].fillna(train['CompetitionOpenSinceMonth'].mode().iloc[0])\r\n",
    "# train['CompetitionOpenSinceYear'] = train['CompetitionOpenSinceYear'].fillna(train['CompetitionOpenSinceYear'].mode().iloc[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "# train.to_csv(\"../data/test_store_combined.csv\",index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "train.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count    Dtype          \n",
      "---  ------                     --------------    -----          \n",
      " 0   Store                      1017209 non-null  int64          \n",
      " 1   DayOfWeek                  1017209 non-null  int64          \n",
      " 2   Date                       1017209 non-null  datetime64[ns] \n",
      " 3   Sales                      1017209 non-null  int64          \n",
      " 4   Customers                  1017209 non-null  int64          \n",
      " 5   Open                       1017209 non-null  int64          \n",
      " 6   Promo                      1017209 non-null  int64          \n",
      " 7   StateHoliday               1017209 non-null  object         \n",
      " 8   SchoolHoliday              1017209 non-null  int64          \n",
      " 9   Year                       1017209 non-null  int64          \n",
      " 10  Month                      1017209 non-null  int64          \n",
      " 11  Day                        1017209 non-null  int64          \n",
      " 12  StoreType                  1017209 non-null  object         \n",
      " 13  Assortment                 1017209 non-null  object         \n",
      " 14  CompetitionDistance        1014567 non-null  float64        \n",
      " 15  CompetitionOpenSinceMonth  693861 non-null   float64        \n",
      " 16  CompetitionOpenSinceYear   693861 non-null   float64        \n",
      " 17  Promo2                     1017209 non-null  int64          \n",
      " 18  Promo2SinceWeek            509178 non-null   float64        \n",
      " 19  Promo2SinceYear            509178 non-null   float64        \n",
      " 20  PromoInterval              509178 non-null   object         \n",
      " 21  weekend                    1017209 non-null  int64          \n",
      " 22  MonthState                 1017209 non-null  int64          \n",
      " 23  To                         1017209 non-null  timedelta64[ns]\n",
      " 24  After                      1017209 non-null  timedelta64[ns]\n",
      "dtypes: datetime64[ns](1), float64(5), int64(13), object(4), timedelta64[ns](2)\n",
      "memory usage: 194.0+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# train_cleaned_ready=train.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# train_cleaned_ready[\"To\"]=pd.to_numeric(train_cleaned_ready['To'].dt.days, downcast='integer')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "train[\"To\"]=pd.to_numeric(train['To'].dt.days, downcast='integer')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "train[\"After\"]=pd.to_numeric(train['After'].dt.days, downcast='integer')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# train_cleaned_ready[\"After\"]=pd.to_numeric(train_cleaned_ready['After'].dt.days, downcast='integer')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# train_cleaned_ready.drop([\"Store\",\"Date\",\"Customers\"],axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "# def encode_scale_features(df,columns):\r\n",
    "#     lb=LabelEncoder()\r\n",
    "#     norm = StandardScaler()\r\n",
    "#     for i in columns:\r\n",
    "#         df[i]=lb.fit_transform(df[i])   \r\n",
    "#     norm_fit = norm.fit_transform(df)\r\n",
    "#     out=pd.DataFrame(norm_fit,columns=df.columns)\r\n",
    "#     return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# features=encode_scale_features(train_cleaned_ready,[\"StoreType\",\"StateHoliday\",\"Assortment\",\"PromoInterval\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# y=features[\"Sales\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "# features=features.drop(\"Sales\",axis=1,inplace=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "\r\n",
    "\r\n",
    "import sys, os\r\n",
    "\r\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\r\n",
    "from Create_modelss_modified import CreateModel\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "import mlflow\r\n",
    "import mlflow.sklearn\r\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "#    features, y, test_size=0.4, random_state=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "\r\n",
    "# mlflow.sklearn.autolog()\r\n",
    "\r\n",
    "# with mlflow.start_run(run_name=\"Baseline_LinearRegression\"):\r\n",
    "#     model=LinearRegression()\r\n",
    "#     model.fit(X_train, y_train)\r\n",
    "\r\n",
    "#     pred = model.predict(X_test)\r\n",
    "    \r\n",
    "#     error=mean_squared_error(y_test,pred)\r\n",
    "#     print(error)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# linearmodel=CreateModel(X_train=X_train,X_test=X_test, y_train=y_train,y_test=y_test,data_version=\"v1\",name=\"LinearRegressionModel\",model=LinearRegression)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# linearmodel.train()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# params = {'fit_intercept': [True,False],'normalize':[True,False]}\r\n",
    "\r\n",
    "# linearmodel.hyperParameterTune(5,search_space=params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "# param_grid = {\r\n",
    "#     'bootstrap': [True],\r\n",
    "#     'max_depth': [80, 90, 100, 110],\r\n",
    "#     'max_features': [2, 3],\r\n",
    "#     'min_samples_leaf': [3, 4, 5],\r\n",
    "#     'min_samples_split': [8, 10, 12],\r\n",
    "#     'n_estimators': [100, 200, 300, 1000]\r\n",
    "# }\r\n",
    "\r\n",
    "# regressionModel=CreateModel(X_train=X_train,X_test=X_test, y_train=y_train,y_test=y_test,data_version=\"v1\",name=\"RandomForestRegressorModel\",model=RandomForestRegressor)  \r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# regressionModel.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "\r\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "from sklearn.utils.validation import check_is_fitted\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "class CustomMaxImputer(BaseEstimator,TransformerMixin):\r\n",
    "    def fit(self, X, y=0):\r\n",
    "        self.fill_value  = X.max()\r\n",
    "        return self\r\n",
    "    def transform(self, X,y=0):\r\n",
    "        return np.where(X.isna(), self.fill_value, X)\r\n",
    "\r\n",
    "        \r\n",
    "    # def fit(self, X, y=None):\r\n",
    "        \r\n",
    "    #     impute_map = X.groupby(self.group_cols)[self.target].agg(self.metric) \\\r\n",
    "    #                                                         .reset_index(drop=False)\r\n",
    "        \r\n",
    "    #     self.impute_map_ = impute_map\r\n",
    "        \r\n",
    "    #     return self \r\n",
    "    \r\n",
    "    # def transform(self, X, y=None):\r\n",
    "        \r\n",
    "    #     # make sure that the imputer was fitted\r\n",
    "    #     check_is_fitted(self, 'impute_map_')\r\n",
    "        \r\n",
    "    #     X = X.copy()\r\n",
    "        \r\n",
    "    #     for index, row in self.impute_map_.iterrows():\r\n",
    "    #         ind = (X[self.group_cols] == row[self.group_cols]).all(axis=1)\r\n",
    "    #         X.loc[ind, self.target] = X.loc[ind, self.target].fillna(row[self.target])\r\n",
    "        \r\n",
    "    #     return X.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# train_cleaned_ready.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# train = pd.read_csv('../data/train_store_combined.csv')\r\n",
    "\r\n",
    "\r\n",
    "y = train[['Sales']]\r\n",
    "X = train.drop(['Sales',\"Customers\",\"Store\",\"Date\"], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "class DenseTransformer(TransformerMixin):\r\n",
    "\r\n",
    "    def fit(self, X, y=None, **fit_params):\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X, y=None, **fit_params):\r\n",
    "        return X.todense()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "def optimize_df(dataframe: pd.DataFrame) -> pd.DataFrame:\r\n",
    "    \"\"\"\r\n",
    "       A simple function which optimizes the data types of the dataframe and returns it\r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        dataframe:\r\n",
    "            Type: pd.DataFrame\r\n",
    "\r\n",
    "        Returns\r\n",
    "        -------\r\n",
    "        pd.DataFrame\r\n",
    "    \"\"\"\r\n",
    "    data_types = dataframe.dtypes\r\n",
    "    optimizable = ['float64', 'int64']\r\n",
    "    for col in data_types.index:\r\n",
    "        if(data_types[col] in optimizable):\r\n",
    "            if(data_types[col] == 'float64'):\r\n",
    "                # downcasting a float column\r\n",
    "                dataframe[col] = pd.to_numeric(\r\n",
    "                    dataframe[col], downcast='float')\r\n",
    "            elif(data_types[col] == 'int64'):\r\n",
    "                # downcasting an integer column\r\n",
    "                dataframe[col] = pd.to_numeric(\r\n",
    "                    dataframe[col], downcast='unsigned')\r\n",
    "\r\n",
    "    return dataframe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# X=optimize_df(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "test=CustomMaxImputer().fit_transform(X[[\"Promo2SinceWeek\",\"CompetitionDistance\",\"Promo2SinceYear\"]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1017209, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# t2=categorical_transformer.fit_transform(X[['StateHoliday', 'PromoInterval', 'Assortment','StoreType']])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# t2.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# nu=numeric_transformer.fit_transform(X[['DayOfWeek', 'Open',\"Promo\",\"SchoolHoliday\",\"Year\",\"CompetitionOpenSinceMonth\",\"CompetitionOpenSinceYear\",\"weekend\",\"MonthState\",\"To\",\"After\",\"Month\",\"Day\",\"Promo2\"]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# nu.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "# y=StandardScaler().fit_transform(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "numeric_features = ['DayOfWeek', 'Open',\"Promo\",\"SchoolHoliday\",\"Year\",\"CompetitionOpenSinceMonth\",\"CompetitionOpenSinceYear\",\"weekend\",\"MonthState\",\"To\",\"After\",\"Month\",\"Day\",\"Promo2\"]\r\n",
    "numeric_transformer = Pipeline(steps=[\r\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\r\n",
    "    ('scaler', StandardScaler())])\r\n",
    "\r\n",
    "max_features=[\"Promo2SinceWeek\",\"CompetitionDistance\",\"Promo2SinceYear\"]\r\n",
    "max_transformenr=Pipeline(steps=[\r\n",
    "    ('imputer', CustomMaxImputer()),\r\n",
    "    ('scaler', StandardScaler())]\r\n",
    ")\r\n",
    "\r\n",
    "categorical_features = ['StateHoliday', 'PromoInterval', 'Assortment','StoreType']\r\n",
    "\r\n",
    "categorical_transformer =Pipeline(steps=[\r\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\r\n",
    "    ('encoder',OneHotEncoder())\r\n",
    "    ]) \r\n",
    "\r\n",
    "preprocessor = ColumnTransformer(\r\n",
    "    transformers=[\r\n",
    "        ('num', numeric_transformer, numeric_features),\r\n",
    "        ('max', max_transformenr, max_features),\r\n",
    "        ('cat', categorical_transformer, categorical_features)\r\n",
    "        ])\r\n",
    "\r\n",
    "# Append classifier to preprocessing pipeline.\r\n",
    "# Now we have a full prediction pipeline.\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\r\n",
    "                                                    random_state=0)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# mlflow.sklearn.autolog()\r\n",
    "\r\n",
    "# with mlflow.start_run(run_name=\"Baseline_LinearRegression\"):\r\n",
    "        \r\n",
    "#     clf = Pipeline(steps=[('preprocessor', preprocessor),\r\n",
    "#                         ('classifier', LinearRegression())])\r\n",
    "#     clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "#     pred = clf.predict(X_test)\r\n",
    "#     error=mean_squared_error(y_test,pred)\r\n",
    "\r\n",
    "# print(\"mean_squared_error of model is \",error)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# import math\r\n",
    "# math.sqrt(error)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "# clf.score(X_test,y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "# result_df = X_test.copy()\r\n",
    "# result_df[\"Prediction Sales\"] = pred\r\n",
    "# result_df[\"Actual Sales\"] = y_test\r\n",
    "# result_df[\"Store\"]=test[\"Store\"]\r\n",
    "# result_agg = result_df.groupby(\"Store\").agg({\"Prediction Sales\": \"mean\", \"Actual Sales\":\"mean\"})\r\n",
    "        \r\n",
    "    \r\n",
    "def pred_graph(res_dataframe):\r\n",
    "    \r\n",
    "    fig = plt.figure(figsize=(18, 5))\r\n",
    "    sns.lineplot(x = res_dataframe.index, y = res_dataframe[\"Actual Sales\"], label='Actual')\r\n",
    "    sns.lineplot(x = res_dataframe.index, y = res_dataframe[\"Prediction Sales\"], label='Prediction')\r\n",
    "    plt.xticks(fontsize=14)\r\n",
    "    plt.yticks(fontsize=14)\r\n",
    "    plt.xlabel(xlabel=\"Day\", fontsize=16)\r\n",
    "    plt.ylabel(ylabel=\"Sales\", fontsize=16)\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "# pred_graph(result_agg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "\r\n",
    "\r\n",
    "# mlflow.sklearn.autolog()\r\n",
    "\r\n",
    "# with mlflow.start_run(run_name=\"Baseline_RandomForest\"):\r\n",
    "        \r\n",
    "#     clf = Pipeline(steps=[('preprocessor', preprocessor),\r\n",
    "#                         ('classifier', RandomForestRegressor(n_estimators=50))])\r\n",
    "#     clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "#     pred = clf.predict(X_test)\r\n",
    "#     error=mean_squared_error(y_test,pred)\r\n",
    "    \r\n",
    "#     mlflow.log_metric(\"mean_squared_error\", error)\r\n",
    "\r\n",
    "# print(\"mean_squared_error of model is \",error)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# result_df = X_test.copy()\r\n",
    "# result_df[\"Prediction Sales\"] = pred\r\n",
    "# result_df[\"Actual Sales\"] = y_test\r\n",
    "# result_df[\"Store\"]=test[\"Store\"]\r\n",
    "# result_agg = result_df.groupby(\"Day\").agg({\"Prediction Sales\": \"mean\", \"Actual Sales\":\"mean\"})\r\n",
    "\r\n",
    "# pred_graph(result_agg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "\r\n",
    "# result_month_agg = result_df.groupby(\"Month\").agg({\"Prediction Sales\": \"mean\", \"Actual Sales\":\"mean\"})\r\n",
    "\r\n",
    "# pred_graph(result_month_agg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "\r\n",
    "# from sklearn.metrics import mean_absolute_error\r\n",
    "\r\n",
    "\r\n",
    "# mean_absolute_error(y_test,pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "mlflow.sklearn.autolog()\r\n",
    "param_grid = {\r\n",
    "    'classifier__bootstrap': [True],\r\n",
    "    'classifier__max_depth': [5, 6, 7, 8],\r\n",
    "    'classifier__max_features': [2, 3],\r\n",
    "    'classifier__min_samples_leaf': [3, 4, 5],\r\n",
    "    'classifier__min_samples_split': [4, 5, 6],\r\n",
    "    'classifier__n_estimators': [8, 10, 15]\r\n",
    "}\r\n",
    "with mlflow.start_run(run_name=\"Hyperparameter_RandomForest\"):\r\n",
    "        \r\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\r\n",
    "                        ('classifier', RandomForestRegressor())])\r\n",
    "\r\n",
    "    grid=GridSearchCV(clf,\r\n",
    "                    param_grid=param_grid,\r\n",
    "                    cv=2,\r\n",
    "                    refit=True)\r\n",
    "\r\n",
    "    grid.fit(X_train, y_train)\r\n",
    "\r\n",
    "    pred = grid.predict(X_test)\r\n",
    "    error=mean_squared_error(y_test,pred)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"mean_squared_error\", error)\r\n",
    "\r\n",
    "print(\"mean_squared_error of model is \",error)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/07/31 10:56:26 WARNING mlflow.utils: Truncated the value of the key `estimator`. Truncated value: `Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImpute...`\n",
      "2021/07/31 11:53:19 INFO mlflow.sklearn.utils: Logging the 5 best runs, 283 runs will be omitted.\n",
      "2021/07/31 11:53:19 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                    ...`\n",
      "2021/07/31 11:53:19 WARNING mlflow.utils: Truncated the value of the key `preprocessor`. Truncated value: `ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('sca...`\n",
      "2021/07/31 11:53:19 WARNING mlflow.utils: Truncated the value of the key `preprocessor__transformers`. Truncated value: `[('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('scaler', StandardScaler())]), ['DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'Year', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'weeken...`\n",
      "2021/07/31 11:53:19 WARNING mlflow.utils: Truncated the value of the key `preprocessor__cat`. Truncated value: `Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('encoder', OneHotEncoder()),\n",
      "                ('to_dense',\n",
      "                 <__main__.DenseTransformer object at 0x000002039B8A4B20>),\n",
      "                ('scaler',...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                    ...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor`. Truncated value: `ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('sca...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor__transformers`. Truncated value: `[('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('scaler', StandardScaler())]), ['DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'Year', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'weeken...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor__cat`. Truncated value: `Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('encoder', OneHotEncoder()),\n",
      "                ('to_dense',\n",
      "                 <__main__.DenseTransformer object at 0x000002039B8A4B20>),\n",
      "                ('scaler',...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                    ...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor`. Truncated value: `ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('sca...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor__transformers`. Truncated value: `[('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('scaler', StandardScaler())]), ['DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'Year', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'weeken...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor__cat`. Truncated value: `Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('encoder', OneHotEncoder()),\n",
      "                ('to_dense',\n",
      "                 <__main__.DenseTransformer object at 0x000002039B8A4B20>),\n",
      "                ('scaler',...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                    ...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor`. Truncated value: `ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('sca...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor__transformers`. Truncated value: `[('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('scaler', StandardScaler())]), ['DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'Year', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'weeken...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor__cat`. Truncated value: `Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('encoder', OneHotEncoder()),\n",
      "                ('to_dense',\n",
      "                 <__main__.DenseTransformer object at 0x000002039B8A4B20>),\n",
      "                ('scaler',...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                    ...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor`. Truncated value: `ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('sca...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor__transformers`. Truncated value: `[('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('scaler', StandardScaler())]), ['DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'Year', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'weeken...`\n",
      "2021/07/31 11:53:20 WARNING mlflow.utils: Truncated the value of the key `preprocessor__cat`. Truncated value: `Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('encoder', OneHotEncoder()),\n",
      "                ('to_dense',\n",
      "                 <__main__.DenseTransformer object at 0x000002039B8A4B20>),\n",
      "                ('scaler',...`\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean_squared_error of model is  5992877.187413464\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "# grid.named_steps['preprocessor'].get_feature_names()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "\r\n",
    "pickle.dump(grid.best_estimator_, open(\"../models/model.pkl\", 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "# import mlflow\r\n",
    "# logged_model = 'runs:/a51ed4226c684518a93c953976e02c73/best_estimator'\r\n",
    "\r\n",
    "# # Load model as a PyFuncModel.\r\n",
    "# loaded_model = mlflow.sklearn.load_model(logged_model)\r\n",
    "\r\n",
    "# # Predict on a Pandas DataFrame.\r\n",
    "# import pandas as pd\r\n",
    "# loadedPrediction=loaded_model.predict(X_test)\r\n",
    "\r\n",
    "# error=mean_squared_error(y_test,loadedPrediction)\r\n",
    "\r\n",
    "\r\n",
    "# print(\"mean_squared_error of model is \",error)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mean_squared_error of model is  5992877.187413464\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "featuereImportances=grid.best_estimator_._final_estimator.feature_importances_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "featuereImportances"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.21883014, 0.35968648, 0.11797289, 0.00139657, 0.00223462,\n",
       "       0.00294832, 0.00242975, 0.12895025, 0.00205845, 0.00714361,\n",
       "       0.00440871, 0.00738972, 0.00317091, 0.00322927, 0.00865306,\n",
       "       0.0126015 , 0.00639352, 0.01632117, 0.03921286, 0.00875331,\n",
       "       0.00541566, 0.00079722, 0.00248091, 0.00104864, 0.00715067,\n",
       "       0.00262711, 0.00534416, 0.00192558, 0.01740714, 0.00062811,\n",
       "       0.0013897 ])"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "features = pd.DataFrame((featuereImportances).transpose() , index=train.columns.tolist(), columns=['importance'])\r\n",
    "features.sort_values('importance', ascending=False)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Shape of passed values is (31, 1), indices imply (25, 1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1680\u001b[1;33m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1681\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (31, 1), indices imply (25, 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-a9c0bb12e334>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatuereImportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'importance'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'importance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    556\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1685\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"values\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1687\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (31, 1), indices imply (25, 1)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "ohe = (grid.best_estimator_.named_steps['preprocessor']\r\n",
    "         .named_transformers_['cat'])\r\n",
    "feature_names = ohe.get_feature_names(input_features=categorical_features)\r\n",
    "feature_names = np.r_[feature_names, numeric_features]\r\n",
    "\r\n",
    "tree_feature_importances = (\r\n",
    "    grid.best_estimator_.named_steps['classifier'].feature_importances_)\r\n",
    "sorted_idx = tree_feature_importances.argsort()\r\n",
    "\r\n",
    "y_ticks = np.arange(0, len(feature_names))\r\n",
    "fig, ax = plt.subplots()\r\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\r\n",
    "ax.set_yticks(y_ticks)\r\n",
    "ax.set_yticklabels(feature_names[sorted_idx])\r\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\r\n",
    "fig.tight_layout()\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'get_feature_names'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-296b8fa79883>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m ohe = (grid.best_estimator_.named_steps['preprocessor']\n\u001b[0;32m      2\u001b[0m          .named_transformers_['cat'])\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "loaded_model.feature_importances_"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'feature_importances_'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-79a9866df6ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3ebe1e15dab481e38dbc50cacd21ed8ec6b22a54b0f3cb3b993bb569cf9c8bed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}